<!DOCTYPE html>
<html>
    <head>
        <script type="text/javascript">
            var host = 'www.valentinmihov.com';
            if ((host == window.location.host) && (window.location.protocol != "https:"))
                window.location.protocol = "https";
        </script>
        <meta charset="utf-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
        <title>Adult Income Data Set Analysis with IPython</title>
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="description" content="The personal blog of Valentin Mihov. Mostly technical stuff around software.
" />
        <link rel="canonical" href="http://localhost:4000/2015/04/17/adult-income-data-set/" />
        <meta content="Valentin Mihov's Blog" property="og:site_name">

  <meta content="Adult Income Data Set Analysis with IPython" property="og:title">


  <meta content="article" property="og:type">


  <meta content="An example workflow for analyzing a data set with ipython and building a logistic regression model over it" property="og:description">


  <meta content="http://localhost:4000/2015/04/17/adult-income-data-set/" property="og:url">


  <meta content="2015-04-17T21:20:14+03:00" property="article:published_time">
  <meta content="http://localhost:4000/about/" property="article:author">


  <meta content="http://localhost:4000/images/87173a37d2b301a20a55ac042aaf6444.jpg" property="og:image">


  


  
  <meta content="python" property="article:tag">
  
  <meta content="notebook" property="article:tag">
  
  <meta content="machine learning" property="article:tag">
  
  <meta content="logistic regression" property="article:tag">
  
  <meta content="matplotlib" property="article:tag">
  
  <meta content="data analysis" property="article:tag">
  


        <!-- Harmony styles -->
        <link rel="stylesheet" type="text/css" href="/assets/css/main.css" />
        <link rel="stylesheet" type="text/css" href="/assets/css/anchor.css" />

        <!-- Modernizr js -->
        <script async src="/assets/js/modernizr.js"></script>

        <!-- IE Fixes -->
        <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
        <!--[if lt IE 9]>
          <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
          <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
        <![endif]-->
    </head>
    <body class="theme-base-01">
        <header class="main-header">
            <div class="wc-container">
                <h1><a href="/">Valentin Mihov's Blog</a></h1>
                <h2>Random pieces of wisdom about technology</h2>
                <ul>
	<li>
		<a href="http://localhost:4000/about">About</a><span>/</span>
	</li>
	<li>
		<a href="http://localhost:4000/blog">Blog</a><span>/</span>
	</li>
	<li>
		<a title="Valentin Mihov on Github" 
			href="https://github.com/valo" target="_blank">
			Github
		</a><span>/</span>
	</li>
</ul>

            </div>
        </header>
        <div class="page-content wc-container">

	<div class="post">
		
		<h1>Adult Income Data Set Analysis with IPython</h1>
		<p class="post-meta">
			
	    <span class="post-date">
    	Apr 17, 2015
	    </span>
		</p>
		<div class="post">
			<p>In this blog post I will show you how to slice-n-dice the data set from <a href="https://archive.ics.uci.edu/ml/datasets/Adult">Adult
Data Set MLR</a> which contains
income data for about 32000 people. We will look at the data and build a machine
learning model (a <a href="http://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>),
which tries to predict if a person will make more than $50K a
year, given data like education, gender and martial status.</p>

<p>Let’s first import some libraries that we are going to need for our analysis</p>

<p><strong>In [1]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">statsmodels</span> <span class="kn">as</span> <span class="nn">sm</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="kn">as</span> <span class="nn">skl</span>
<span class="kn">import</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">as</span> <span class="nn">preprocessing</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="kn">as</span> <span class="nn">linear_model</span>
<span class="kn">import</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">as</span> <span class="nn">cross_validation</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="kn">as</span> <span class="nn">metrics</span>
<span class="kn">import</span> <span class="nn">sklearn.tree</span> <span class="kn">as</span> <span class="nn">tree</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="kn">as</span> <span class="nn">sns</span></code></pre></figure>

<p>First we need to read the data from the file, which contains comma separated
columns. With the command below we will read the data skipping any spaces
before/after the commas and mark the values ‘?’ as missing data points.</p>

<h2 id="load-the-data">Load the data</h2>

<p><strong>In [2]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">original_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span>
    <span class="s">"adult.data.txt"</span><span class="p">,</span>
    <span class="n">names</span><span class="o">=</span><span class="p">[</span>
        <span class="s">"Age"</span><span class="p">,</span> <span class="s">"Workclass"</span><span class="p">,</span> <span class="s">"fnlwgt"</span><span class="p">,</span> <span class="s">"Education"</span><span class="p">,</span> <span class="s">"Education-Num"</span><span class="p">,</span> <span class="s">"Martial Status"</span><span class="p">,</span>
        <span class="s">"Occupation"</span><span class="p">,</span> <span class="s">"Relationship"</span><span class="p">,</span> <span class="s">"Race"</span><span class="p">,</span> <span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Capital Gain"</span><span class="p">,</span> <span class="s">"Capital Loss"</span><span class="p">,</span>
        <span class="s">"Hours per week"</span><span class="p">,</span> <span class="s">"Country"</span><span class="p">,</span> <span class="s">"Target"</span><span class="p">],</span>
        <span class="n">sep</span><span class="o">=</span><span class="s">r'</span><span class="err">\</span><span class="s">s*,</span><span class="err">\</span><span class="s">s*'</span><span class="p">,</span>
        <span class="n">engine</span><span class="o">=</span><span class="s">'python'</span><span class="p">,</span>
        <span class="n">na_values</span><span class="o">=</span><span class="s">"?"</span><span class="p">)</span>
<span class="n">original_data</span><span class="o">.</span><span class="n">tail</span><span class="p">()</span></code></pre></figure>

<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Age</th>
      <th>Workclass</th>
      <th>fnlwgt</th>
      <th>Education</th>
      <th>Education-Num</th>
      <th>Martial Status</th>
      <th>Occupation</th>
      <th>Relationship</th>
      <th>Race</th>
      <th>Sex</th>
      <th>Capital Gain</th>
      <th>Capital Loss</th>
      <th>Hours per week</th>
      <th>Country</th>
      <th>Target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>32556</th>
      <td> 27</td>
      <td>      Private</td>
      <td> 257302</td>
      <td> Assoc-acdm</td>
      <td> 12</td>
      <td> Married-civ-spouse</td>
      <td>      Tech-support</td>
      <td>      Wife</td>
      <td> White</td>
      <td> Female</td>
      <td>     0</td>
      <td> 0</td>
      <td> 38</td>
      <td> United-States</td>
      <td> &lt;=50K</td>
    </tr>
    <tr>
      <th>32557</th>
      <td> 40</td>
      <td>      Private</td>
      <td> 154374</td>
      <td>    HS-grad</td>
      <td>  9</td>
      <td> Married-civ-spouse</td>
      <td> Machine-op-inspct</td>
      <td>   Husband</td>
      <td> White</td>
      <td>   Male</td>
      <td>     0</td>
      <td> 0</td>
      <td> 40</td>
      <td> United-States</td>
      <td>  &gt;50K</td>
    </tr>
    <tr>
      <th>32558</th>
      <td> 58</td>
      <td>      Private</td>
      <td> 151910</td>
      <td>    HS-grad</td>
      <td>  9</td>
      <td>            Widowed</td>
      <td>      Adm-clerical</td>
      <td> Unmarried</td>
      <td> White</td>
      <td> Female</td>
      <td>     0</td>
      <td> 0</td>
      <td> 40</td>
      <td> United-States</td>
      <td> &lt;=50K</td>
    </tr>
    <tr>
      <th>32559</th>
      <td> 22</td>
      <td>      Private</td>
      <td> 201490</td>
      <td>    HS-grad</td>
      <td>  9</td>
      <td>      Never-married</td>
      <td>      Adm-clerical</td>
      <td> Own-child</td>
      <td> White</td>
      <td>   Male</td>
      <td>     0</td>
      <td> 0</td>
      <td> 20</td>
      <td> United-States</td>
      <td> &lt;=50K</td>
    </tr>
    <tr>
      <th>32560</th>
      <td> 52</td>
      <td> Self-emp-inc</td>
      <td> 287927</td>
      <td>    HS-grad</td>
      <td>  9</td>
      <td> Married-civ-spouse</td>
      <td>   Exec-managerial</td>
      <td>      Wife</td>
      <td> White</td>
      <td> Female</td>
      <td> 15024</td>
      <td> 0</td>
      <td> 40</td>
      <td> United-States</td>
      <td>  &gt;50K</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="analyze-the-data">Analyze the data</h2>

<p>Let’s plot the distribution of each feature, so that we have a better
understanding what we have in our data. We draw the number of values for each
category feature and the histogram of the values for each continuous feature.</p>

<p><strong>In [3]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">cols</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">original_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">cols</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">original_data</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">original_data</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="nb">object</span><span class="p">:</span>
        <span class="n">original_data</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">"bar"</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">original_data</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="s">"vertical"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span></code></pre></figure>

<p><img src="/notebooks/adult_income_data_set_files/adult_income_data_set_7_0.png" alt="png" /></p>

<p>As you can see from the plots above our data is mostly concentrated in the USA
with mostly male white people. This is a good thing to notice, as it may impact
the conclusions we come to later.</p>

<p><strong>In [4]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="p">(</span><span class="n">original_data</span><span class="p">[</span><span class="s">"Country"</span><span class="p">]</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span> <span class="o">/</span> <span class="n">original_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">head</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>United-States    0.895857
Mexico           0.019748
Philippines      0.006081
Germany          0.004207
Canada           0.003716
dtype: float64
</code></pre>
</div>

<p>Indeed! 89% of the samples are for people from the US. Mexico comes next
with less than 2%.</p>

<p>Now, let’s explore something else. The correlation between the different
features. Generally it is not a good idea to have many correlated features, as
it might be a sign that your data is not very good. For this purpose
we will need to encode the categorical features as numbers. This can be done
using the <code class="highlighter-rouge">LabelEncoder</code> in the <code class="highlighter-rouge">scikit-learn</code> package.</p>

<p><strong>In [5]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c"># Encode the categorical features as numbers</span>
<span class="k">def</span> <span class="nf">number_encode_features</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
    <span class="n">encoders</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">column</span> <span class="ow">in</span> <span class="n">result</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">result</span><span class="o">.</span><span class="n">dtypes</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="nb">object</span><span class="p">:</span>
            <span class="n">encoders</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span>
            <span class="n">result</span><span class="p">[</span><span class="n">column</span><span class="p">]</span> <span class="o">=</span> <span class="n">encoders</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">result</span><span class="p">[</span><span class="n">column</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">encoders</span>

<span class="c"># Calculate the correlation and plot it</span>
<span class="n">encoded_data</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">number_encode_features</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">encoded_data</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p><img src="/notebooks/adult_income_data_set_files/adult_income_data_set_11_0.png" alt="png" /></p>

<p>We see there is a high correlation between <code class="highlighter-rouge">Education</code> and <code class="highlighter-rouge">Education-Num</code>.
Let’s look at these columns</p>

<p><strong>In [6]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">original_data</span><span class="p">[[</span><span class="s">"Education"</span><span class="p">,</span> <span class="s">"Education-Num"</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span></code></pre></figure>

<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Education</th>
      <th>Education-Num</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0 </th>
      <td>    Bachelors</td>
      <td> 13</td>
    </tr>
    <tr>
      <th>1 </th>
      <td>    Bachelors</td>
      <td> 13</td>
    </tr>
    <tr>
      <th>2 </th>
      <td>      HS-grad</td>
      <td>  9</td>
    </tr>
    <tr>
      <th>3 </th>
      <td>         11th</td>
      <td>  7</td>
    </tr>
    <tr>
      <th>4 </th>
      <td>    Bachelors</td>
      <td> 13</td>
    </tr>
    <tr>
      <th>5 </th>
      <td>      Masters</td>
      <td> 14</td>
    </tr>
    <tr>
      <th>6 </th>
      <td>          9th</td>
      <td>  5</td>
    </tr>
    <tr>
      <th>7 </th>
      <td>      HS-grad</td>
      <td>  9</td>
    </tr>
    <tr>
      <th>8 </th>
      <td>      Masters</td>
      <td> 14</td>
    </tr>
    <tr>
      <th>9 </th>
      <td>    Bachelors</td>
      <td> 13</td>
    </tr>
    <tr>
      <th>10</th>
      <td> Some-college</td>
      <td> 10</td>
    </tr>
    <tr>
      <th>11</th>
      <td>    Bachelors</td>
      <td> 13</td>
    </tr>
    <tr>
      <th>12</th>
      <td>    Bachelors</td>
      <td> 13</td>
    </tr>
    <tr>
      <th>13</th>
      <td>   Assoc-acdm</td>
      <td> 12</td>
    </tr>
    <tr>
      <th>14</th>
      <td>    Assoc-voc</td>
      <td> 11</td>
    </tr>
  </tbody>
</table>
</div>

<p>As you can see these two columns actually represent the same features, but
encoded as strings and as numbers. We don’t need the string representation, so
we can just delete this column. Note that it is a much better option to delete
the <code class="highlighter-rouge">Education</code> column as the <code class="highlighter-rouge">Education-Num</code> has the important property that
the values are ordered: the higher the number, the higher the education that
person has. This is a vaulable information a machine learning algorithm can use.</p>

<p><strong>In [7]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">del</span> <span class="n">original_data</span><span class="p">[</span><span class="s">"Education"</span><span class="p">]</span></code></pre></figure>

<p>So it seems that the data is mostly OK with the exception of <code class="highlighter-rouge">Sex</code> and
<code class="highlighter-rouge">Relationship</code>, which seems to be negatively correlated. Let’s explore that for
a bit</p>

<p><strong>In [8]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">original_data</span><span class="p">[[</span><span class="s">"Sex"</span><span class="p">,</span> <span class="s">"Relationship"</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span></code></pre></figure>

<div style="max-height:1000px;max-width:1500px;overflow:auto;">
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Sex</th>
      <th>Relationship</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0 </th>
      <td>   Male</td>
      <td> Not-in-family</td>
    </tr>
    <tr>
      <th>1 </th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
    <tr>
      <th>2 </th>
      <td>   Male</td>
      <td> Not-in-family</td>
    </tr>
    <tr>
      <th>3 </th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
    <tr>
      <th>4 </th>
      <td> Female</td>
      <td>          Wife</td>
    </tr>
    <tr>
      <th>5 </th>
      <td> Female</td>
      <td>          Wife</td>
    </tr>
    <tr>
      <th>6 </th>
      <td> Female</td>
      <td> Not-in-family</td>
    </tr>
    <tr>
      <th>7 </th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
    <tr>
      <th>8 </th>
      <td> Female</td>
      <td> Not-in-family</td>
    </tr>
    <tr>
      <th>9 </th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
    <tr>
      <th>10</th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
    <tr>
      <th>11</th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
    <tr>
      <th>12</th>
      <td> Female</td>
      <td>     Own-child</td>
    </tr>
    <tr>
      <th>13</th>
      <td>   Male</td>
      <td> Not-in-family</td>
    </tr>
    <tr>
      <th>14</th>
      <td>   Male</td>
      <td>       Husband</td>
    </tr>
  </tbody>
</table>
</div>

<p>Yes. The data looks correlated, because for example <code class="highlighter-rouge">Male</code> and <code class="highlighter-rouge">Husband</code> are
highly correlated values, as well as <code class="highlighter-rouge">Female</code> and <code class="highlighter-rouge">Wife</code>. There is no easy way
to tackle this problem, so let’s carry on.</p>

<h2 id="build-a-classifier">Build a classifier</h2>

<p>Now that we explored our data, let’s try to build a classifier which tries to
predict what will be the income of a given person given the features we have in
our dataset.</p>

<p>First we need to encode the features as numbers as the classifiers cannot work
with string features. As we saw a while ago this can be achieved easily with the
function we defined earlier. Let’s encode the data and show the histograms of
the values again.</p>

<p><strong>In [9]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">encoded_data</span><span class="p">,</span> <span class="n">encoders</span> <span class="o">=</span> <span class="n">number_encode_features</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">15</span><span class="p">))</span>
<span class="n">cols</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">rows</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">encoded_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">cols</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">column</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">encoded_data</span><span class="o">.</span><span class="n">columns</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="n">rows</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">column</span><span class="p">)</span>
    <span class="n">encoded_data</span><span class="p">[</span><span class="n">column</span><span class="p">]</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">axes</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">rotation</span><span class="o">=</span><span class="s">"vertical"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span></code></pre></figure>

<p><img src="/notebooks/adult_income_data_set_files/adult_income_data_set_20_0.png" alt="png" /></p>

<p>As you can see we have our data properly encoded and it seems to make sense.
Now, let’s try to build a classifier for it. Before we do that, let’s split the
data into a train and test set. This is a common approach to avoid overfitting.
If we train and test the classifiers on the same data we will always get awesome
results and we will most probably overfit the model. However if we test a
classifier on data it has never seen we can be more confident it will perform
better when ran on new data.</p>

<h2 id="split-and-scale-the-features">Split and scale the features</h2>

<p>Most machine learning algorithms like the features to be scaled with mean 0 and
variance 1. This is called “removing the mean and scaling to unit variance”.
This can be easily done with the <code class="highlighter-rouge">StandardScaler</code> from <code class="highlighter-rouge">scikit-learn</code>. Let’s
scale the features and look at them again.</p>

<p><strong>In [10]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">encoded_data</span><span class="p">[</span><span class="n">encoded_data</span><span class="o">.</span><span class="n">columns</span> <span class="o">-</span> <span class="p">[</span><span class="s">"Target"</span><span class="p">]],</span> <span class="n">encoded_data</span><span class="p">[</span><span class="s">"Target"</span><span class="p">],</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.70</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"f64"</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s">"f64"</span><span class="p">))</span></code></pre></figure>

<h3 id="logistic-regression">Logistic regression</h3>

<p><strong>In [11]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cls</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">cls</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cls</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">12</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">"d"</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">encoders</span><span class="p">[</span><span class="s">"Target"</span><span class="p">]</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">encoders</span><span class="p">[</span><span class="s">"Target"</span><span class="p">]</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Real value"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Predicted value"</span><span class="p">)</span>
<span class="k">print</span> <span class="s">"F1 score: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">skl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">cls</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">coefs</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">coefs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">"bar"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>F1 score: 0.573306
</code></pre>
</div>

<p><img src="/notebooks/adult_income_data_set_files/adult_income_data_set_25_1.png" alt="png" /></p>

<p>As you can see we managed to achieve F1 score of 0.57 and the features that
seems to contribute most positively to have an income of more than $50K are
<code class="highlighter-rouge">Capital Gain</code>, <code class="highlighter-rouge">Education-Num</code> and <code class="highlighter-rouge">Sex</code>, while the features that contribute
most negatively are <code class="highlighter-rouge">Martia Status</code> and <code class="highlighter-rouge">Relationship</code>. There is a problem here,
though. Features like <code class="highlighter-rouge">Martial Status</code> have values ranging from 0 to 6 and the
order is really important here. In practice there is no particular order in that
feature (unlike <code class="highlighter-rouge">Education-Num</code> for which the higher the number, the better the
education). We can fix this using <em>binary features</em>.</p>

<h3 id="classify-using-binary-features">Classify using binary features</h3>

<p>As a last step we can try to improve our classifier using binary attributes. Our
current approach for encoding our data has the drawback that we put arbitrary
order in our classes. For example we encode <code class="highlighter-rouge">Relationship</code> with a number between
1 and 5 and the logistic regression interprets these values as continuous
variables and plugs them into an optimization function. This will cause
different classes to have different weight into our model, which is not correct.
Each class is theoretically equally weighted compared to the rest of the
classes. In order to fix this we can use dummy variables.</p>

<p><strong>In [12]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">binary_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">original_data</span><span class="p">)</span>
<span class="c"># Let's fix the Target as it will be converted to dummy vars too</span>
<span class="n">binary_data</span><span class="p">[</span><span class="s">"Target"</span><span class="p">]</span> <span class="o">=</span> <span class="n">binary_data</span><span class="p">[</span><span class="s">"Target_&gt;50K"</span><span class="p">]</span>
<span class="k">del</span> <span class="n">binary_data</span><span class="p">[</span><span class="s">"Target_&lt;=50K"</span><span class="p">]</span>
<span class="k">del</span> <span class="n">binary_data</span><span class="p">[</span><span class="s">"Target_&gt;50K"</span><span class="p">]</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">binary_data</span><span class="o">.</span><span class="n">corr</span><span class="p">(),</span> <span class="n">square</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p><img src="/notebooks/adult_income_data_set_files/adult_income_data_set_28_0.png" alt="png" /></p>

<p>Now we have a bunch of features that have only the values 0 and 1. There is a
lot of correlation between some of them, but let’s not look at this for now (for
example Male and Female are negatively correlated).</p>

<p><strong>In [13]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">binary_data</span><span class="p">[</span><span class="n">binary_data</span><span class="o">.</span><span class="n">columns</span> <span class="o">-</span> <span class="p">[</span><span class="s">"Target"</span><span class="p">]],</span> <span class="n">binary_data</span><span class="p">[</span><span class="s">"Target"</span><span class="p">],</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.70</span><span class="p">)</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span></code></pre></figure>

<h3 id="logistic-regression-with-dummy-variables">Logistic Regression with dummy variables</h3>

<p><strong>In [14]:</strong></p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">cls</span> <span class="o">=</span> <span class="n">linear_model</span><span class="o">.</span><span class="n">LogisticRegression</span><span class="p">()</span>

<span class="n">cls</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">cls</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">cm</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">fmt</span><span class="o">=</span><span class="s">"d"</span><span class="p">,</span> <span class="n">xticklabels</span><span class="o">=</span><span class="n">encoders</span><span class="p">[</span><span class="s">"Target"</span><span class="p">]</span><span class="o">.</span><span class="n">classes_</span><span class="p">,</span> <span class="n">yticklabels</span><span class="o">=</span><span class="n">encoders</span><span class="p">[</span><span class="s">"Target"</span><span class="p">]</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Real value"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Predicted value"</span><span class="p">)</span>
<span class="k">print</span> <span class="s">"F1 score: </span><span class="si">%</span><span class="s">f"</span> <span class="o">%</span> <span class="n">skl</span><span class="o">.</span><span class="n">metrics</span><span class="o">.</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
<span class="n">coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">cls</span><span class="o">.</span><span class="n">coef_</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">coefs</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">coefs</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="s">"bar"</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<div class="highlighter-rouge"><pre class="highlight"><code>F1 score: 0.651455
</code></pre>
</div>

<p><img src="/notebooks/adult_income_data_set_files/adult_income_data_set_32_1.png" alt="png" /></p>

<h1 id="summary">Summary</h1>

<p>We managed to improve the <a href="http://en.wikipedia.org/wiki/F1_score">F1 score</a> significantly by converting the data to use
dummy variables. Also it seems that we managed to uncover some interesting
insight from our model. It seems that the features that impacts the income of a
person positively are <code class="highlighter-rouge">Capital Gain</code>, <code class="highlighter-rouge">Married-civ-spounce</code>, <code class="highlighter-rouge">Age</code>, <code class="highlighter-rouge">Hours per
week</code> and <code class="highlighter-rouge">Exec-managerial</code>. The features that impact it most negatively are
<code class="highlighter-rouge">Never married</code>, <code class="highlighter-rouge">Own child</code>, <code class="highlighter-rouge">Priv-house-serv</code>, <code class="highlighter-rouge">Divorsed</code> and unfortunately
<code class="highlighter-rouge">Female</code>. One more proof that there is a gender inequality in our society.</p>

<p>As you can see we not only managed to build a machine learning model that we can
use to classify new data, but we also managed to uncover some interesting
insight from our data. This is one of the nice features of the linear models.
They are not “black boxes”, like neural networks for example and allow to see
what exactly the model is doing.</p>

<p>You can download the ipython notebook, which was used for generating the above
analysis from <a href="/notebooks/adult_income_data_set.ipynb">here</a>.</p>


			<div class="share-page">
			    Share this on &rarr;
			    <a href="https://twitter.com/intent/tweet?text=Adult+Income+Data+Set+Analysis+with+IPython&amp;url=http%3A%2F%2Flocalhost%3A4000%2F2015%2F04%2F17%2Fadult-income-data-set%2F&amp;via=valentinmihov&amp;related=valentinmihov" rel="nofollow" target="_blank" title="Share on Twitter">Twitter</a>
			    <a href="https://facebook.com/sharer.php?u=http://localhost:4000/2015/04/17/adult-income-data-set/" rel="nofollow" target="_blank" title="Share on Facebook">Facebook</a>
			    <a href="https://plus.google.com/share?url=http://localhost:4000/2015/04/17/adult-income-data-set/" rel="nofollow" target="_blank" title="Share on Google+">Google+</a>
			</div>
		</div>
	</div>

	
	<div class="related">
		<h4>Related Posts</h2>
		<ul class="posts">
		    
		    <li>
			  <span>12 Sep 2016 &raquo;</span>
			  <a href="http://localhost:4000/2016/09/12/fullstackfest-2016-recap/">Full Stack Fest 2016 Recap</a>
		    </li>
		    
		    <li>
			  <span>15 Nov 2015 &raquo;</span>
			  <a href="http://localhost:4000/2015/11/15/microservices-dev-environment-with-docker/">Development environment for microservices with docker-compose</a>
		    </li>
		    
		    <li>
			  <span>24 Apr 2015 &raquo;</span>
			  <a href="http://localhost:4000/2015/04/24/aws-machine-learning-overview/">AWS Machine Learning Overview</a>
		    </li>
		    
		</ul>
	</div>
	

	<div class="comments">
		

<button class="show-comments">Load Disqus comments</button>

<div id="disqus_thread"></div>

<script type="text/javascript" src="https://code.jquery.com/jquery-1.11.2.min.js"></script>
<script type="text/javascript">
$(document).ready(function() {
    $('.show-comments').on('click', function(){
          var disqus_shortname = 'valentinmihov'; // Replace this value with *your* username.

          var d = document, s = d.createElement('script');

          s.src = '//' + disqus_shortname + '.disqus.com/embed.js';

          s.setAttribute('data-timestamp', +new Date());
          (d.head || d.body).appendChild(s);

          // hide the button once comments load
          $(this).fadeOut();
    });
});
</script>


	</div>

	<div class="post-footer">
		<div class="column-1">
			
				<a href="http://localhost:4000/2015/01/27/view_vs_feature_specs_what_to_use/"><< Older</a>
			
		</div>
		<div class="column-2"><a href="http://localhost:4000/ ">Home</a></div>
		<div class="column-3">
			
				<a href="http://localhost:4000/2015/04/24/aws-machine-learning-overview/">Newer >></a>
			
		</div>
	</div>
</div>

        <footer class="main-footer">
            <div class="wc-container">
                <div class="column one">
                    <h6>Few more links</h6>
<ul class="menu">
    <li><a href="http://localhost:4000/about">About</a></li>
    <li><a href="http://localhost:4000/blog">Blog</a></li>
</ul>		

                </div>
                <div class="column two">
                    <h6>Follow me</h6>

<ul class="social-media">


    
    <li>
        <a title="valentinmihov on Twitter"
            href="https://twitter.com/valentinmihov"
            class="twitter wc-img-replace" target="_blank">Twitter</a>
    </li>
    

    
    <li>
        <a title="valo on Github"
            href="https://github.com/valo"
            class="github wc-img-replace" target="_blank">Github</a>
    </li>
    

    
    <li>
        <a title="valentin.mihov1 on Facebook"
            href="https://facebook.com/valentin.mihov1"
            class="facebook wc-img-replace" target="_blank">Facebook</a>
    </li>
    

    
    <li>
        <a title="+ValentinMihov on Google Plus"
            href="https://plus.google.com/+ValentinMihov"
            class="google wc-img-replace" target="_blank">Google</a>
    </li>
    

    

    

</ul>

                </div>
            </div>
            <p class="wc-container disclaimer">
                
	Everything you find here under Creative Commons CC0.         

Powered by <a href="http://jekyllrb.com" target="_blank">Jekyll</a>
            </p>
        </footer>
        <script type="text/javascript">
          /* To avoid render blocking css */
          var cb = function() {
            var l = document.createElement('link'); l.rel = 'stylesheet';
            l.href = '//fonts.googleapis.com/css?family=Ubuntu+Mono&subset=latin';
            var h = document.getElementsByTagName('head')[0]; h.parentNode.insertBefore(l, h);
          };
          var raf = requestAnimationFrame || mozRequestAnimationFrame ||
              webkitRequestAnimationFrame || msRequestAnimationFrame;
          if (raf) raf(cb);
          else window.addEventListener('load', cb);
        </script>
        <!-- jQuery -->
        <script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
        <!-- When no internet load JQuery from local -->
        <script>window.jQuery || document.write('<script src="/assets/js/jquery.min.js"><\/script>')</script>
        <!-- Site js -->
        <script src="/assets/js/anchor.min.js"></script>
        <script src="/assets/js/all.js"></script>
        <!-- Google analytics  -->
        
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-9529494-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

    </body>
</html>
